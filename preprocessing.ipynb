{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Default settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# config defaults\n",
    "default_config = {\n",
    "    \"SKULLSTRIP\": \"1\",\n",
    "    \"DVARS\": \"1\",\n",
    "    \"SLICETIME\": \"1\",\n",
    "    \"MOTCOR\": \"1\",\n",
    "    \"NORM\": \"1\",\n",
    "    \"SMOOTH\": \"6\", # gaussian smoothing kernel size in mm\n",
    "    \"MOTREG\": \"1\",\n",
    "    \"DVARS\": \"1\",\n",
    "    \"FD\": \"1\",\n",
    "    \"TEMPLATE\": \"/usr/local/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz\",\n",
    "    \"OUTLIER\": \"UNION\" # union, intersect, dvars, fd, none\n",
    "}"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "# Support functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirstruct(output):\n",
    "    import pathlib \n",
    "    import os\n",
    "\n",
    "    pathlib.Path(os.path.join(output, \"func\"     )).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(os.path.join(output, \"anat\"     )).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(os.path.join(output, \"spat_norm\")).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(os.path.join(output, \"motion\"   )).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exist(filepath, type=\"any\"):\n",
    "    if type=='f':\n",
    "        type='file'\n",
    "    elif type=='d':\n",
    "        type='dir'\n",
    "\n",
    "    if type=='file':\n",
    "        from os.path import isfile as exists\n",
    "    elif type==\"dir\":\n",
    "        from os.path import isdir as exists\n",
    "    elif type==\"any\":\n",
    "        from os.path import exists\n",
    "    else:\n",
    "        raise Exception(\"type '\" + type + \"' is invalid.\")\n",
    "    \n",
    "    return(exists(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(text, keywords, split=\"=\"):\n",
    "    key, val = text.split(\"=\")\n",
    "    if key not in keywords:\n",
    "        raise Exception(\"Input doesn't contain any of the specified key words\")\n",
    "    return(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_chars(text, first, last):\n",
    "    text = \"{}\".format(text[1:] if text.startswith(first) else text)\n",
    "    text = \"{}\".format(text[:-1] if text.endswith(last) else text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(text, keywords, split=\"=\", first=\"[\", last=\"]\"):\n",
    "    key, val = parse_line(text, keywords, split)\n",
    "    val = strip_chars(val, \"[\", \"]\")\n",
    "    return(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_defaults(config_dict, defaults):\n",
    "    default_keys=[key for key in defaults.keys()]\n",
    "\n",
    "    restore_defaults=[key not in config_dict.keys() for key in default_keys]\n",
    "    restore_defaults=list(filter(lambda x: restore_defaults[x], range(len(restore_defaults))))\n",
    "    restore_defaults=[default_keys[i] for i in restore_defaults]\n",
    "\n",
    "    for key in restore_defaults:\n",
    "        config_dict[key] = defaults[key]\n",
    "\n",
    "    return(config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_input_line(line, keywords):\n",
    "    input_dict = {}\n",
    "    items = line.split(\",\")\n",
    "    \n",
    "    for item in items:\n",
    "        item=item.strip()\n",
    "        \n",
    "        try:\n",
    "            key, val = parse_input(item, keywords) # keywords must be enterest as a list\n",
    "            input_dict[key] = val\n",
    "        except:\n",
    "            print(\"Error:\", item)\n",
    "\n",
    "    # check if all the files exist \n",
    "    if not check_exist(input_dict[\"FUNC\"], \"file\"):\n",
    "        raise Exception(input_dict[\"FUNC\"] + \" is not a valid filepath.\")\n",
    "    if not check_exist(input_dict[\"ANAT\"], \"file\"):\n",
    "        raise Exception(input_dict[\"ANAT\"] + \" is not a valid filepath.\")\n",
    "       \n",
    "    return(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret input\n",
    "def interpret_input(filepath):\n",
    "    import pandas as pd\n",
    "\n",
    "    input=open(filepath, \"r\")\n",
    "    lines=input.readlines()\n",
    "\n",
    "    keywords = [\"FUNC\", \"ANAT\", \"OUTPUT\"]\n",
    "    input_df = pd.DataFrame(index=range(len(lines)), columns=keywords)\n",
    "\n",
    "    for line, ind in zip(lines, range(len(lines))):\n",
    "        line=line.strip()\n",
    "        input_dict=interpret_input_line(line, keywords)\n",
    "\n",
    "        input_df.loc[ind,\"FUNC\"  ] = input_dict[\"FUNC\"]\n",
    "        input_df.loc[ind,\"ANAT\"  ] = input_dict[\"ANAT\"]\n",
    "        input_df.loc[ind,\"OUTPUT\"] = input_dict[\"OUTPUT\"]\n",
    "\n",
    "    return(input_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret config\n",
    "def interpret_config(filepath):\n",
    "    config=open(filepath, \"r\")\n",
    "    lines=config.readlines()\n",
    "\n",
    "    keywords=[\"SKULLSTRIP\",\"DVARS\", \"FD\", \"SLICETIME\",\"MOTCOR\",\"NORM\", \"SMOOTH\", \"MOTREG\", \"OUTLIER\", \"TEMPLATE\"]\n",
    "\n",
    "    config_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        try:\n",
    "            key, val = parse_input(line, keywords) # keywords must be enterest as a list\n",
    "            config_dict[key] = val\n",
    "        except:\n",
    "            print(\"Error:\", line)\n",
    "\n",
    "    config_dict = check_defaults(config_dict, default_config)\n",
    "    return(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afni2nifti(filepath, rm_orig=True):\n",
    "    import os\n",
    "    \n",
    "    nii_filepath=os.path.join(os.path.dirname(filepath), rm_ext(filepath))+\".nii\"\n",
    "    os.system(\"3dAFNItoNIFTI -prefix {} {}\".format(nii_filepath, filepath+\"*.HEAD\"))\n",
    "    if rm_orig:\n",
    "        os.system(\"rm {}*.HEAD\".format(filepath))\n",
    "        os.system(\"rm {}*.BRIK\".format(filepath))\n",
    "    return(nii_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTR(filepath):\n",
    "    import subprocess\n",
    "    \n",
    "    tr=subprocess.check_output(\"fslval {} pixdim4\".format(filepath), shell=True)\n",
    "    tr=tr.decode(\"utf-8\")\n",
    "    tr=tr.rstrip()\n",
    "    return(tr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_ext(filename):\n",
    "    from os.path import splitext\n",
    "    from os.path import basename\n",
    "    \n",
    "    filename=basename(filename)\n",
    "    newpath=splitext(filename)[0]\n",
    "    \n",
    "    if \".\" in newpath:\n",
    "        newpath=rm_ext(newpath)\n",
    "    return(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(filename):\n",
    "    from os.path import splitext\n",
    "    from os.path import basename\n",
    "\n",
    "    filename=basename(filename)\n",
    "    newname, ext=splitext(filename)\n",
    "    \n",
    "    if \".\" in newname:\n",
    "        ext = get_ext(newname) + ext\n",
    "    return(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_mm2sigma(mm):\n",
    "    sigma=mm/2.35482004503\n",
    "    return(sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which(list, x=True):\n",
    "    coords=[]\n",
    "    iter=0\n",
    "    \n",
    "    for elem in list:\n",
    "        if elem == x:\n",
    "            coords.append(iter)\n",
    "        iter+=1\n",
    "    return(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gzip_file(filename):\n",
    "    import gzip\n",
    "    import shutil\n",
    "    \n",
    "    with open(filename, 'rb') as f_in:\n",
    "        with gzip.open(filename+'.gz', 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    return(filename+'.gz')"
   ]
  },
  {
   "source": [
    "# Preprocessing Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brainroi(img, out_dir):\n",
    "    import os\n",
    "\n",
    "    roi_img = os.path.join(out_dir, \"roi_\"+os.path.basename(img))\n",
    "    os.system(\"robustfov -i {} -r {}\".format(img, roi_img))\n",
    "\n",
    "    return(roi_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skullstrip(img, out_dir):\n",
    "    import os\n",
    "\n",
    "    out_dir  = os.path.join(out_dir, \"anat\")\n",
    "    out_file = \"brain_\" + rm_ext(img)\n",
    "    skullstr = os.path.join(out_dir, out_file)\n",
    "\n",
    "    print(\"SKULLSTRIPPING - skipped\")\n",
    "\n",
    "    # os.system(\"bet {} {} -R\".format(img, skullstr))\n",
    "    return(skullstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicetime(img, out_dir):\n",
    "    import os\n",
    "\n",
    "    tr=getTR(img)\n",
    "    tshift_path=os.path.join(out_dir, \"func\", \"t_\" + rm_ext(img))\n",
    "    \n",
    "    print(\"SLICETIME CORRECTION - skipped\")\n",
    "    # os.system(\"3dTshift -TR {}s -prefix {} {}\".format(tr, tshift_path, img))\n",
    "\n",
    "    tshift_path=afni2nifti(tshift_path)\n",
    "    return(tshift_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motcor(img, out_dir):\n",
    "    import os\n",
    "\n",
    "    prefix=\"m\"\n",
    "\n",
    "    motcor_path=os.path.join(out_dir, \"func\", \"m_\"+os.path.basename(img))\n",
    "    _1dfile_path=os.path.join(out_dir, \"motion\", \"1d_\"+os.path.splitext(os.path.basename(img))[0]+\".1D\")\n",
    "\n",
    "    print(\"MOTION CORRECTION - skipped\")\n",
    "    # os.system(\"3dvolreg -base 0 -prefix {} -1Dfile {} {}\".format(motcor_path, _1dfile_path, img))\n",
    "    # afni2nifti(motcor_path)\n",
    "\n",
    "    return(motcor_path, _1dfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new spatial normalization\n",
    "def spatnorm(f_img, a_img, template, out_dir):\n",
    "    print(\"SPATIAL NORMALIZATION - skipped\")\n",
    "    import os\n",
    "\n",
    "    # lin warp func to struct\n",
    "    print(\"       + Linear-warping functional to structural...\")\n",
    "    l_func_omat=os.path.join(out_dir, \"spat_norm\", \"func2str.mat\")\n",
    "    # os.system(\"flirt -ref {} -in {} -omat {} -dof 6\".format(a_img, f_img, l_func_omat))\n",
    "    \n",
    "    # lin warp struct to template\n",
    "    print(\"       + Linear-warping structural to standard template...\")\n",
    "    l_anat_img =os.path.join(out_dir, \"anat\", \"l_\" + os.path.basename(a_img))\n",
    "    l_anat_omat=os.path.join(out_dir, \"spat_norm\", \"aff_str2std.mat\")\n",
    "    # os.system(\"flirt -ref {} -in {} -omat {} -out {}\".format(template, a_img, l_anat_omat, l_anat_img))\n",
    "    \n",
    "    # non-lin warp struct to template\n",
    "    print(\"       + Non-linear-warping structural to standard template...\")\n",
    "    nl_anat_img  =os.path.join(out_dir, \"anat\", \"n\" + os.path.basename(l_anat_img))\n",
    "    cout_anat_img=os.path.join(out_dir, \"anat\", \"cout_\" + os.path.basename(nl_anat_img))\n",
    "    # os.system(\"fnirt --ref={} --in={} --aff={} --iout={} --cout={} --subsamp=2,2,2,1\".format(template, a_img, l_anat_omat, nl_anat_img,cout_anat_img))\n",
    "    \n",
    "    # make binary mask from non-lin warped image\n",
    "    print(\"       + Creating binary mask from non-linearly warped image...\")\n",
    "    bin_nl_anat_img=os.path.join(out_dir, \"anat\", \"bin_\" + os.path.basename(nl_anat_img))\n",
    "    # os.system(\"fslmaths {} -bin {}\".format(nl_anat_img, bin_nl_anat_img))\n",
    "    \n",
    "    # apply std warp to func data\n",
    "    print(\"       + Applying standardized warp to functional data...\")\n",
    "    nl_func_img=os.path.join(out_dir, \"func\", \"nl_\"+os.path.basename(f_img))\n",
    "    # os.system(\"applywarp --ref={} --in={} --out={} --warp={} --premat={}\".format(template, f_img, nl_func_img, cout_anat_img, l_func_omat))\n",
    "\n",
    "    # remove unwanted files\n",
    "\n",
    "    return(nl_anat_img, nl_func_img) # anat, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spat_smooth(img, mm, out_dir):\n",
    "    import os\n",
    "\n",
    "    print(\"SMOOTHING FUNCTIONAL DATA - skipped\")\n",
    "    \n",
    "    sigma=gauss_mm2sigma(mm)\n",
    "    s_img=os.path.join(out_dir, \"s_\"+os.path.basename(img))\n",
    "    \n",
    "    # os.system(\"fslmaths {} -kernel gauss {} -fmean {}\".format(img, sigma, s_img))\n",
    "    return(s_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motreg(img, _1d, out_dir):\n",
    "\timport os\n",
    "\n",
    "\tprint(\"MOTION REGRESSION - skipped\")\n",
    "\n",
    "\terror_img =os.path.join(out_dir, \"error_\"  + rm_ext(img) + \".nii\")\n",
    "\tmotreg_img=os.path.join(out_dir, \"motreg_\" + rm_ext(img) + \".nii\")\n",
    "\n",
    "\t# os.system(\n",
    "\t# \"3dDeconvolve \\\n",
    "\t# \t-input {} \\\n",
    "\t# \t-num_stimts 6 \\\n",
    "\t# \t-stim_file 1 {}'[0]' -stim_base 1 -stim_label 1 roll  \\\n",
    "\t# \t-stim_file 2 {}'[1]' -stim_base 2 -stim_label 2 pitch \\\n",
    "\t# \t-stim_file 3 {}'[2]' -stim_base 3 -stim_label 3 yaw   \\\n",
    "\t# \t-stim_file 4 {}'[3]' -stim_base 4 -stim_label 4 dS    \\\n",
    "\t# \t-stim_file 5 {}'[4]' -stim_base 5 -stim_label 5 dL    \\\n",
    "\t# \t-stim_file 6 {}'[5]' -stim_base 6 -stim_label 6 dP    \\\n",
    "\t# \t-fitts {} \\\n",
    "\t# \t-errts {}\".format(img, _1d, _1d, _1d, _1d, _1d, _1d, motreg_img, error_img))\n",
    "\n",
    "\t# error_img =afni2nifti(error_img)\n",
    "\t# motreg_img=afni2nifti(motreg_img)\n",
    "\n",
    "\treturn(motreg_img, error_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deg2mm(_1d_file):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from math import pi\n",
    "\n",
    "    rad = 50 # radius of head in mm\n",
    "    circum = 2 * pi * rad\n",
    "\n",
    "    MPEs = pd.read_csv(_1d_file, sep=r\"\\s+\", header=None)\n",
    "    MPEs.columns = ['roll', 'pitch', 'yaw', 'dS', 'dL', 'dP']\n",
    "    MPEs.loc[:,['dS', 'dL', 'dP']] = circum * (MPEs.loc[:,['dS', 'dL', 'dP']] / 360)\n",
    "\n",
    "    out_file = os.path.join(os.path.dirname(_1d_file), \"mm_\"+os.path.basename(_1d_file))\n",
    "    \n",
    "    MPEs.to_csv(out_file, sep=\"\\t\")\n",
    "\n",
    "    return(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meantsBOLD(func_img, mot_dir):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    dvars_txt = os.path.join(mot_dir, \"dvars.txt\")\n",
    "    dvars_png = os.path.join(mot_dir, \"dvars.png\")\n",
    "\n",
    "    out_compound = os.path.join(mot_dir, \"dvars_outliers.txt\")\n",
    "\n",
    "    os.system(\"fsl_motion_outliers -i {} -o {} -s {} -p {} --nomoco\".format(func_img, out_compound, dvars_txt, dvars_png))\n",
    "\n",
    "    # append extra 0\n",
    "    # dvars_out=open(out_compound, \"a\")\n",
    "    # dvars_out.write(\"0\")\n",
    "    # dvars_out.close()\n",
    "\n",
    "    dvars_out=pd.read_csv(out_compound, delim_whitespace=True, header=0)\n",
    "    dvars_out=dvars_out.sum(axis=1)\n",
    "    dvars_out=dvars_out.astype(\"int\")\n",
    "\n",
    "    dvars_out.to_csv(out_compound, sep=\"\\t\", index=False)\n",
    "\n",
    "    return(out_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_out(path, voxel_size):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    fd_data    = pd.read_csv(path, sep=\"\\t\", index_col = 0, header=0)\n",
    "    voxel_size = min([float(i) for i in voxel_size.split(\"\\t\")])\n",
    "\n",
    "    out_file = os.path.join(os.path.dirname(path), \"fd_outliers.txt\")\n",
    "\n",
    "    out_ind = (fd_data > voxel_size).sum(axis=1)\n",
    "    out_ind = out_ind.astype('int')\n",
    "    out_ind.to_csv(out_file, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    return(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-28-be6b1eca36da>, line 23)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-be6b1eca36da>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    return(os.path.join(out_dir, \"outliers.txt\")\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def mk_outliers(dvars, fd, out_dir, method=\"union\"):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    print(\"FLAGGING OUTLIERS\")\n",
    "\n",
    "    fd_mat    = pd.read_csv(fd   , delimiter=\"\\t\", header=None)\n",
    "    dvars_mat = pd.read_csv(dvars, delimiter=\"\\t\", header=None)\n",
    "\n",
    "    if method.lower()==\"union\":\n",
    "        outliers_mat = (fd_mat + dvars_mat).astype(\"bool\")\n",
    "        outliers_mat = outliers_mat.astype(\"int\")\n",
    "    elif method.lower()==\"intersect\":\n",
    "        outliers_mat = dvars_mat[0]*fd_mat[0]\n",
    "        outliers_mat = outliers_mat.dropna()\n",
    "    elif method.lower()==\"fd\":\n",
    "        outliers_mat = fd_mat\n",
    "    elif method.lower()==\"dvars\":\n",
    "        outliers_mat = dvars_mat\n",
    "    \n",
    "    outliers_mat.to_csv(os.path.join(out_dir, \"outliers.txt\"), sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    return(os.path.join(out_dir, \"outliers.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_time(img, out, int_ind, return_full=False):\n",
    "    import numpy as np\n",
    "\n",
    "    if len(img.shape)!=4:\n",
    "        raise Exception(\"Nifti image must have 4 dimensions.\")\n",
    "    \n",
    "    # make blank image\n",
    "    int_dim = list(img.shape[0:3])\n",
    "    int_dim.append(int_ind[1]-int_ind[0]-1)\n",
    "    int_img = np.empty(int_dim)\n",
    "\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            for slice in range(img.shape[2]):\n",
    "                int_val = interp_pts(img[row, col, slice, int_ind[0]], img[row, col, slice, int_ind[1]], int_ind[1]-int_ind[0]-1)\n",
    "                int_img[row, col, slice, :] = int_val\n",
    "\n",
    "    if return_full:\n",
    "        img[:,:,:,out] = int_img\n",
    "        return(img)\n",
    "    else:\n",
    "        return(int_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_pts(start, end, nvals, round=True):\n",
    "    \n",
    "    step_len=(end-start)/(nvals+1)\n",
    "    \n",
    "    interp_set=[start+(step_len*i) for i in range(1,nvals+1)]\n",
    "    if round:\n",
    "        interp_set=round_dec(interp_set, [start, end])\n",
    "\n",
    "    return(interp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_dec(vals, ref):\n",
    "    import decimal\n",
    "\n",
    "    n_places=max([n_dec(i) for i in ref])\n",
    "    rnd_vals=[round(i, n_places) for i in vals]\n",
    "\n",
    "    return(rnd_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_dec(val):\n",
    "    import decimal\n",
    "\n",
    "    n_places=abs(decimal.Decimal(str(val)).as_tuple().exponent)\n",
    "    return(n_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding_timepoints(t_range, ind):\n",
    "\n",
    "    import numpy as np\n",
    "    \n",
    "    sub_ind = np.empty((0,2), dtype=int, order='C')\n",
    "    \n",
    "    for ii in ind:\n",
    "        t_start = ii-1\n",
    "        t_end   = ii+1\n",
    "        \n",
    "        while t_start in ind:\n",
    "            t_start -= 1\n",
    "        while t_end in ind:\n",
    "            t_end += 1\n",
    "        \n",
    "        if t_start < min(t_range):\n",
    "            t_start = \"NaN\"\n",
    "        if t_end < min(t_range):\n",
    "            t_end = \"NaN\"\n",
    "        \n",
    "        sub_ind = np.vstack([sub_ind, (t_start, t_end)])\n",
    "        sub_ind = np.unique(sub_ind, axis=0)\n",
    "    return(sub_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrubbing(nifti, outliers, out_dir, interpolate=False):\n",
    "    import os\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    from pandas import read_csv\n",
    "    from nibabel.testing import data_path\n",
    "    from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "    print(\"SCRUBBING fMRI TIME SERIES\")\n",
    "    print(outliers)\n",
    "\n",
    "    img = nib.load(nifti)\n",
    "    mat = img.get_fdata()\n",
    "\n",
    "    outliers=read_csv(outliers, delimiter=\"\\t\", header=None)\n",
    "    outliers=outliers.values.tolist()\n",
    "    outliers=which([o[0] for o in outliers], 1)\n",
    "\n",
    "    print(\"       + Removing outlier timepoints...\")\n",
    "    mat[:,:,:,outliers]=float(\"NaN\")\n",
    "\n",
    "    if interpolate:\n",
    "        print(\"       + Linearly-interpolating outliers...\")\n",
    "        sub_ind = surrounding_timepoints(range(mat.shape[3]), outliers)\n",
    "\n",
    "        for oo in range(len(sub_ind)):\n",
    "            tmp = interp_time(mat, outliers[oo], sub_ind[oo,:], return_full=False)\n",
    "            mat[:,:,:,(sub_ind[oo,0]+1):sub_ind[oo,1]] = tmp\n",
    "\n",
    "    new_img = nib.Nifti1Image(mat, img.affine, header=img.header)\n",
    "    print(\"       + Saving scrubbed timeseries...\")\n",
    "    nib.save(new_img, os.path.join(out_dir, 'n_scrubbed_image.nii'))\n",
    "    \n",
    "    return(os.path.join(out_dir, 'n_scrubbed_image.nii'))\n"
   ]
  },
  {
   "source": [
    "# Wrappers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def wrapper_lvl2(input_file, config_file):\n",
    "    config=interpret_config(config_file)\n",
    "    input =interpret_input(input_file)\n",
    "\n",
    "    nrow = len(input.index)\n",
    "    \n",
    "    for row in range(nrow):\n",
    "        wrapper_lvl1(input.loc[row,:], config)\n",
    "        print(\"\")\n",
    "    return(input, config)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_lvl1(input, config):\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    create_dirstruct(input[\"OUTPUT\"])\n",
    "\n",
    "    cur_func=os.path.join(input[\"OUTPUT\"], \"func\", \"func\" + get_ext(input[\"FUNC\"]))\n",
    "    cur_anat=os.path.join(input[\"OUTPUT\"], \"anat\", \"MPRage\" + get_ext(input[\"ANAT\"]))\n",
    "\n",
    "    os.system(\"cp {} {}\".format(input[\"FUNC\"], cur_func))\n",
    "    os.system(\"cp {} {}\".format(input[\"ANAT\"], cur_anat))\n",
    "\n",
    "    # cur_anat = brainroi(cur_anat, os.path.join(input[\"OUTPUT\"], \"anat\"))\n",
    "\n",
    "    anat_nobet = cur_anat\n",
    "\n",
    "    if config[\"SKULLSTRIP\"]==\"1\":\n",
    "        cur_anat=skullstrip(cur_anat, input[\"OUTPUT\"])\n",
    "    if config[\"SLICETIME\"]==\"1\":\n",
    "        cur_func=slicetime(cur_func, input[\"OUTPUT\"])\n",
    "    if config[\"MOTCOR\"]==\"1\":\n",
    "        cur_func, _1dfile_path=motcor(cur_func, input[\"OUTPUT\"])\n",
    "\n",
    "        voxel_size=subprocess.check_output(\"3dinfo -adi -adj -adk {}\".format(cur_func), shell=True)\n",
    "        voxel_size=voxel_size.decode(\"utf-8\")\n",
    "        voxel_size=voxel_size.rstrip()\n",
    "\n",
    "        mm_1dfile_path=deg2mm(_1dfile_path)\n",
    "    if config[\"FD\"]==\"1\":\n",
    "        os.system(\"Rscript framewise_disp.R --OUT_DIR={} --MPE_MM={} --VOXEL_DIM={}\".format( \\\n",
    "            os.path.join(input[\"OUTPUT\"], \"motion\"), _1dfile_path, voxel_size))\n",
    "        fd_path=os.path.join(input[\"OUTPUT\"], \"motion\", 'motion_FD.csv')\n",
    "        fd_outliers=fd_out(fd_path, voxel_size)\n",
    "    if config[\"DVARS\"]==\"1\":\n",
    "        dvar_out = meantsBOLD(cur_func, os.path.join(input[\"OUTPUT\"], \"motion\"))\n",
    "    if config[\"NORM\"]==\"1\":\n",
    "        cur_anat, cur_func=spatnorm(cur_func, cur_anat, config[\"TEMPLATE\"], input[\"OUTPUT\"])\n",
    "    if float(config[\"SMOOTH\"]) > 0:\n",
    "        cur_func=spat_smooth(cur_func, float(config[\"SMOOTH\"]), os.path.join(input[\"OUTPUT\"], \"func\"))\n",
    "    if config[\"MOTREG\"]==\"1\":\n",
    "        cur_func, err_func=motreg(cur_func, _1dfile_path, os.path.join(input[\"OUTPUT\"], \"func\"))\n",
    "    if config[\"OUTLIER\"].lower()!=\"none\":\n",
    "        outliers=mk_outliers(dvar_out, fd_outliers, os.path.join(input[\"OUTPUT\"], \"motion\"), method=config[\"OUTLIER\"].lower())\n",
    "        scrubbed_nifti=scrubbing(cur_func, outliers, os.path.join(input[\"OUTPUT\"], \"func\"), interpolate=True)\n",
    "\n",
    "    return(input, config)\n"
   ]
  },
  {
   "source": [
    "# TESTING AREA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'wrapper_lvl1' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8414d8d8a7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconfig_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/d/Downloads/ds000031-download/config.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrapper_lvl2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-ecb43c594fa0>\u001b[0m in \u001b[0;36mwrapper_lvl2\u001b[0;34m(input_file, config_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mwrapper_lvl1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wrapper_lvl1' is not defined"
     ]
    }
   ],
   "source": [
    "input_filepath  = \"/mnt/d/Downloads/ds000031-download/input.txt\"\n",
    "config_filepath = \"/mnt/d/Downloads/ds000031-download/config.txt\"\n",
    "\n",
    "input, config=wrapper_lvl2(input_filepath, config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out/func/m_t_func.nii.nii\n/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out/motion/1d_t_func.nii.1D\nMOTION CORRECTION\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out/func/m_t_func.nii.nii',\n",
       " '/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out/motion/1d_t_func.nii.1D')"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "img=\"/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out/func/t_func.nii.nii\"\n",
    "out_dir=\"/mnt/d/Downloads/ds000031-download/sub-01/ses-003/out\"\n",
    "motcor(img, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}